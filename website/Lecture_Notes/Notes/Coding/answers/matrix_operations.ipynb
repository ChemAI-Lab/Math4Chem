{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix operations\n",
    "\n",
    "In this section we are going to review some basic matrix operations in Python. <br>\n",
    "\n",
    "This tutorial can be deployed in <a target=\"_blank\" href=\"https://colab.research.google.com/github/ChemAI-Lab/Math4Chem/blob/main/website/Lecture_Notes/Coding/answers/matrix_operations.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous tutorial, <a target=\"_blank\" href=\"https://colab.research.google.com/github/ChemAI-Lab/Math4Chem/blob/main/website/Lecture_Notes/Coding/intro_linear_algebra.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>, we review some of the most common operations on vectors, including the **dot product**.\n",
    "$$\n",
    "\\mathbf{u}^\\top \\mathbf{v} = \\sum_i^n u_i v_j\n",
    "$$\n",
    "\n",
    "Similarly, we can define the matrix-vector multiplication using the same function we coded previously for the dot product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(u,v):\n",
    "    nu = u.shape[0]\n",
    "    nv = v.shape[0]\n",
    "    \n",
    "    if nu == nv: # check they are the same size\n",
    "        value = 0\n",
    "        for i in range(nu):\n",
    "            value += u[i] * v[i]\n",
    "        return value\n",
    "    else:\n",
    "        raise TypeError(\"Vectors have different size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test our function\n",
    "v = np.random.randint(low=-10, high=10, size=5)\n",
    "u = np.random.randint(low=-10, high=10, size=5)\n",
    "\n",
    "print('dot product(ours): ', dot_product(u, v))\n",
    "print('dot product(Numpy): ', v.T @ u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in class, matrix-vector multiplication can be define in terms of the dot product between the vector and the rows of the matrix.\n",
    "$$\n",
    "\\mathbf{A} \\mathbf{v} =  \\begin{pmatrix}\n",
    "\t\ta_{11}  & a_{12} & \\cdots & a_{1m}  \\\\ \n",
    "\t\ta_{21}  & a_{22} & \\cdots & a_{2m}  \\\\ \n",
    "\t\t\\vdots  &   &   & \\vdots  \\\\ \n",
    "\t\ta_{n1}  & a_{n2} & \\cdots & a_{nm}   \n",
    "\t\t\\end{pmatrix}\\begin{pmatrix}\n",
    "\t\tv_{1}  \\\\ \n",
    "\t\tv_{2}  \\\\ \n",
    "\t\t\\vdots \\\\ \n",
    "\t\tv_{m} \n",
    "\t\t\\end{pmatrix} = \\begin{pmatrix}\n",
    "\t\t\\mathbf{a}_{1}^\\top   \\\\ \n",
    "\t\t\\mathbf{a}_{2}^\\top \\\\ \n",
    "\t\t\\vdots  \\\\ \n",
    "\t\t\\mathbf{a}_{n}^\\top\n",
    "\t\t\\end{pmatrix}\\begin{pmatrix}\n",
    "\t\tv_{1}  \\\\ \n",
    "\t\tv_{2}  \\\\ \n",
    "\t\t\\vdots \\\\ \n",
    "\t\tv_{m} \n",
    "\t\t\\end{pmatrix} = \\begin{pmatrix}\n",
    "\t\t\\mathbf{a}_{1}^\\top \\mathbf{v}  \\\\ \n",
    "\t\t\\mathbf{a}_{2}^\\top \\mathbf{v} \\\\ \n",
    "\t\t\\vdots  \\\\ \n",
    "\t\t\\mathbf{a}_{n}^\\top  \\mathbf{v}\n",
    "\t\t\\end{pmatrix} \n",
    "$$\n",
    "\n",
    "Using this definition, let's code the matrix-vector multiplication function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_vector_multiplication(a,v):\n",
    "    nv = v.shape[0]\n",
    "    n,m  = a.shape\n",
    "\n",
    "    if nv == m: # check they are the same size\n",
    "        \n",
    "        result = np.zeros(n) # how many elements would the result have?\n",
    "        \n",
    "        for j in range(n):\n",
    "            ai = a[j]\n",
    "            result[j] = dot_product(ai,v)\n",
    "        return result\n",
    "    else:\n",
    "        raise TypeError(\"Matrix and vector have different size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test our function\n",
    "v = np.random.randint(low=-2, high=2, size=5)\n",
    "a = np.random.randint(low=-2, high=2, size=(3,5))\n",
    "\n",
    "print(v)\n",
    "print(a)\n",
    "\n",
    "print('matrix-vector(ours): ', matrix_vector_multiplication(a, v))\n",
    "print('matrix-vector product(Numpy): ', a @ v)\n",
    "\n",
    "# what happens when we do a * v ?\n",
    "# print('dot product(Numpy): ', a * v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's consider matrix-matrix multiplication can be define in terms of the dot product between the vector and the rows of the matrix.\n",
    "$$\n",
    "\\mathbf{A} \\mathbf{B} =  \\begin{pmatrix}\n",
    "\t\ta_{11}  & a_{12} & \\cdots & a_{1m}  \\\\ \n",
    "\t\ta_{21}  & a_{22} & \\cdots & a_{2m}  \\\\ \n",
    "\t\t\\vdots  &   &   & \\vdots  \\\\ \n",
    "\t\ta_{n1}  & a_{n2} & \\cdots & a_{nm}   \n",
    "\t\t\\end{pmatrix}\\begin{pmatrix}\n",
    "\t\tb_{11}  & b_{12} & \\cdots & b_{1l}  \\\\ \n",
    "\t\tb_{21}  & b_{22} & \\cdots & b_{2l}  \\\\ \n",
    "\t\t\\vdots  &   &   & \\vdots  \\\\ \n",
    "\t\tb_{m1}  & b_{n2} & \\cdots & b_{ml}   \n",
    "\t\t\\end{pmatrix} =  \\begin{pmatrix}\n",
    "\t\t\\mathbf{a}_{1}^\\top \\mathbf{b}_{1} & \\mathbf{a}_{1}^\\top \\mathbf{b}_{2} & \\cdots & \\mathbf{a}_{1}^\\top \\mathbf{b}_{l}  \\\\ \n",
    "\t\t\\mathbf{a}_{2}^\\top \\mathbf{b}_{2} & \\mathbf{a}_{2}^\\top \\mathbf{b}_{2} & \\cdots & \\mathbf{a}_{2}^\\top \\mathbf{b}_{l}  \\\\  \n",
    "\t\t\\vdots  &   &   & \\vdots  \\\\  \n",
    "\t\t\\mathbf{a}_{n}^\\top \\mathbf{b}_{1} & \\mathbf{a}_{n}^\\top \\mathbf{b}_{2} & \\cdots & \\mathbf{a}_{n}^\\top \\mathbf{b}_{l}  \\\\ \n",
    "\t\t\\end{pmatrix} \n",
    "$$\n",
    "\n",
    "Using our ``matrix_vector_multiplication`` function, let's code the matrix-matrix multiplication function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_matrix_multiplication(a, b):\n",
    "    na, ma = a.shape\n",
    "    nb, mb = a.shape\n",
    "\n",
    "    if na == nb:  # check if the number of columns in a are the same as the number of rows in b\n",
    "\n",
    "        result = np.zeros(shape=(na,mb))  # how many elements would the result have? (na,ma) x (nb,mb) = (na,mb)\n",
    "\n",
    "        for j in range(mb):\n",
    "            bj = b[:,j] # select the column-j of b\n",
    "            result[:,j] = matrix_vector_multiplication(a, bj)\n",
    "        return result\n",
    "    else:\n",
    "        raise TypeError(\"Matrix and vector have different size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test our function\n",
    "b = np.random.randint(low=-2, high=2, size=(5,5))\n",
    "a = np.random.randint(low=-2, high=2, size=(5, 5))\n",
    "\n",
    "print(a)\n",
    "print('\\n')\n",
    "print(b)\n",
    "print('\\n')\n",
    "\n",
    "print('matrix-matrix(ours): ', matrix_matrix_multiplication(a, b))\n",
    "print('\\n')\n",
    "print('matrix-matrix(Numpy): ', a @ b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing matrices is one of the most important computations in data science and code development as it provides a way to verify our computations.\n",
    "One of the common metrics to compare two matrices is the **Frobenius norm**,\n",
    "$$\n",
    "\\| \\mathbf{X}\\|_{F} = \\sqrt{\\sum_i \\sum_j x^2_{ij}}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{X}$  can be the difference between two matrices, $\\mathbf{X} = \\mathbf{A} - \\mathbf{B}$<br>\n",
    "\n",
    "Some times to code the Frobenius norm differently, using only Numpy functions.<br>\n",
    "\n",
    "(Let's avoid looping over the entire matrix, $\\cancel{\\sum_i \\sum_j}$)<br>\n",
    "1. Use the Numpy function [``flatten()``](https://numpy.org/doc/2.0/reference/generated/numpy.ndarray.flatten.html)\n",
    "2. Use the Numpy function [``sum''](https://numpy.org/doc/stable/reference/generated/numpy.sum.html)\n",
    "   \n",
    "WE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frobenius_norm(A,B):\n",
    "    X = A - B\n",
    "    x_flat = X.flatten()\n",
    "    x2_flat = x_flat**2\n",
    "    return np.sqrt(np.sum(x2_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test our function\n",
    "a = np.random.randint(low=-2, high=2, size=(5, 5))\n",
    "b = np.random.randint(low=-2, high=2, size=(5, 5))\n",
    "\n",
    "print('F norm for A-B', frobenius_norm(a,b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear models\n",
    "\n",
    "In class we covered linear equations. As we will see in the upcoming classes, linear models are the foundation to almost any regression algorithm.<br>\n",
    "Linear models 101:\n",
    "$$\n",
    "\\begin{align}\n",
    "f(x) &= \\mathbf{w}^\\top \\mathbf{x}\n",
    " = \\begin{bmatrix}\n",
    "w_0 & w_1 & \\cdots & w_p \\\\\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    " 1 \\\\\n",
    " x_1 \\\\\n",
    " \\vdots \\\\\n",
    " x_d\n",
    "\\end{bmatrix}=  \\sum_{i=0}^{d} w_i x_i\n",
    "\\end{align} \n",
    "$$\n",
    "\n",
    "this is merely another dot product between, the linear weights $\\mathbf{w} = [a,b]$ and $\\mathbf{x} = [1,x]$.\n",
    "\n",
    "For simple linear regression in a single dimension, the above equation is, \n",
    "$$\n",
    "\\begin{align}\n",
    "f(x) &= \\mathbf{w}^\\top \\mathbf{x}\n",
    " = \\begin{bmatrix}\n",
    "w_0 & w_1 \\\\\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    " 1 \\\\\n",
    " x_1 \n",
    "\\end{bmatrix}=  w_0 + w_1x = b + a\\;x\n",
    "\\end{align} \n",
    "$$\n",
    "\n",
    "Let's generate some random data to see if we can approximate it with a simple linear model.\n",
    "\n",
    "Let's see a linear model under the assumption of matrix-vector multiplication.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{bmatrix}\n",
    "f(\\mathbf{x}_1) \\\\\n",
    "f(\\mathbf{x}_2) \\\\\n",
    "\\vdots \\\\\n",
    "f(\\mathbf{x}_N)\n",
    "\\end{bmatrix} &= \\begin{bmatrix}\n",
    "\\mathbf{w}^\\top \\mathbf{x}_1 \\\\\n",
    "\\mathbf{w}^\\top\\mathbf{x}_2 \\\\\n",
    "\\vdots \\\\\n",
    "\\mathbf{w}^\\top\\mathbf{x}_N\n",
    "\\end{bmatrix}  =  \\begin{bmatrix}\n",
    "\\mathbf{x}_1^\\top \\\\\n",
    "\\mathbf{x}_2^\\top \\\\\n",
    "\\vdots \\\\\n",
    "\\mathbf{x}_N^\\top \\\\\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    " w_0 \\\\\n",
    " w_1 \n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & x_{1} \\\\\n",
    "1 & x_{2} \\\\\n",
    "\\vdots \\\\\n",
    "1 & x_{N} \\\\\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    " w_0 \\\\\n",
    " w_1 \n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "w_0 + w_1\\;x_{1} \\\\\n",
    "w_0 + w_1\\; x_{2} \\\\\n",
    "\\vdots \\\\\n",
    "w_0 + w_1\\;x_{N} \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random data over f(x) = sin(x) + x - 1\n",
    "def get_data(N):\n",
    "    # This creates an array x of N linearly spaced values between -1 and 1.\n",
    "    x = np.linspace(-1., 1., N)\n",
    "    y = np.sin(.5*x) + x - 1.\n",
    "    # Adds random noise to each y value.\n",
    "    y = y + np.random.uniform(low=0., high=0.5, size=x.shape)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_data(25)\n",
    "plt.scatter(x, y, label='data')\n",
    "plt.xlabel(r'$x$', fontsize=18)\n",
    "plt.ylabel(r'$f(x)$', fontsize=18)\n",
    "plt.ylim(-3., 2.)\n",
    "plt.legend()\n",
    "# plt.savefig('Figures/data.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generating Random Parameters**\n",
    "\n",
    "Later in the course, we will see how to ''train'' this family of models, but in the mean time let's use some random parameters.\n",
    "For a one-dimensional model, we only need two parameters, $\\mathbf{w} = [w_0,w_1]$, \n",
    "\n",
    "$$\n",
    "[m,b] \\sim U([-2,2])\n",
    "$$\n",
    "where $U$ is a random distribution between -2 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random parameters\n",
    "def get_random_params():\n",
    "    theta_random = np.random.uniform(low=-2., high=2., size=(2,1))\n",
    "    return theta_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the dot_product or the  function, define a function for the linear model\n",
    "def linear_model(X, w):\n",
    "    y = matrix_vector_multiplication(X,w)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_rnd = get_random_params()\n",
    "b,m = w_rnd\n",
    "print('parameters')\n",
    "print(w_rnd)\n",
    "\n",
    "x_grid = np.linspace(-1., 1., 100)\n",
    "X = np.column_stack((np.ones_like(x_grid),x_grid)) # add a column of ones \n",
    "\n",
    "y_pred = linear_model(X,w_rnd) #prediction with random parameters\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.clear()\n",
    "ax.scatter(x, y,label='data')\n",
    "ax.plot(x_grid,y_pred,color='k',label='model')\n",
    "ax.text(0.1,-2.5,'w0=%.2f, w1=%.2f'%(m,b),fontsize=15)\n",
    "ax.legend(loc=1)\n",
    "ax.set_xlabel(r'$x$', fontsize=18)\n",
    "ax.set_ylabel(r'$f(x)$', fontsize=18)\n",
    "ax.set_ylim(-3., 2.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem3pc3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
