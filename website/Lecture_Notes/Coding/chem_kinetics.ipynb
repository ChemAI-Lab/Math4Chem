{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical Kinetics (review on Linear Equations)\n",
    "\n",
    "In this tutorial, we will review Linear Equations and discuss three different scenarios,\n",
    "1. Normal (same number of columns and rows)\n",
    "2. Overdetermined (more rows than columns)\n",
    "3. Undermined (more columns than rows)\n",
    "  \n",
    "This code will also show us how to solve all these different cases. <br>\n",
    "\n",
    "This tutorial can be deployed in <a target=\"_blank\" href=\"https://colab.research.google.com/github/ChemAI-Lab/Math4Chem/blob/main/website/Lecture_Notes/Coding/chem_kinetics.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Equations\n",
    "\n",
    "A set of linear equations has the following structure,\n",
    "$$\n",
    "\\mathbf{A} \\mathbf{x} = \\mathbf{b}\n",
    "$$\n",
    "where $\\mathbf{A}$ a matrix with $n$-rows and $m$-columns, the vector $\\mathbf{x}$ must have $m$-entries, and $\\mathbf{b}$ is a vector with $n$-entries. <br>\n",
    "We saw this in linear regression where $\\mathbf{x}$ was the vector of the parameters of the model, for example, $\\mathbf{x}^\\top = [a, b]$, and each row of $\\mathbf{A}$ was a single data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Square matrices\n",
    "\n",
    "A square matrix is a matrix that has an equal number of rows and columns,\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\\\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\\\\ a_{n1} & a_{n2} & \\cdots & a_{nn} \\end{bmatrix}\n",
    "$$\n",
    "We can invert a square matrix, $\\mathbf{A}^{-1}\\mathbf{A} = \\mathbf{I}$, where $\\mathbf{I}$ is the identity matrix. <br>\n",
    "* $\\mathbf{A}$ is invertible, if its determinant is not zero.\n",
    "\n",
    "### Solving a system of linear equations using the inverse of a matrix.\n",
    "$$\n",
    "\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\\\\n",
    "\\underbrace{\\mathbf{A}^{-1}\\mathbf{A}}_{\\mathbf{I}} \\mathbf{x} = \\mathbf{A}^{-1}\\mathbf{b}\\\\\n",
    "\\mathbf{x} = \\mathbf{A}^{-1} \\mathbf{b}\n",
    "$$\n",
    "\n",
    "If we can invert $\\mathbf{A}$, we just need to multiply its inverse with $\\mathbf{b}$, to find $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining the Rate Law from Experimental Data\n",
    "\n",
    "To illustrate the solution of Linear equations when $\\mathbf{A}$ is invertible, we are going to use the following example, [link](https://flexbooks.ck12.org/cbook/ck-12-chemistry-flexbook-2.0/section/18.10/primary/lesson/determining-the-rate-law-from-experimental-data-chem/).<br>\n",
    "\n",
    "Let's consider the following reaction,\n",
    "$$\n",
    "2NO(g) + 2H_2(g) \\to N_2(g) + 2H_2O(g)\n",
    "$$\n",
    "\n",
    "Then we collected the following measured the concentrations of this reactions and it's rates, \n",
    "\n",
    "| Experiment | [NO] | [H<sub>2</sub>] | Initial Rate [M/s]\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| 1 | 0.005 | 0.002 | -11.29 |\n",
    "| 2 | 0.01 | 0.002 | -9.90 |\n",
    "| 3 | 0.01 | 0.004 | -9.21 |\n",
    "\n",
    "\n",
    "We can write the rates of the reactions in terms of the concentrations of the reactants using the following rate law,\n",
    "$$\n",
    "r = k [NO]^{\\alpha} [H_2]^{\\beta},\n",
    "$$\n",
    "This equation does not look linear, but using the properties of logarithms we can rewrite it as,\n",
    "\n",
    "$$\n",
    "\\ln r = \\ln k + \\alpha \\ln [NO] + \\beta \\ln [H_2]\n",
    "$$\n",
    "We can solve this system of linear equations to find the values of $\\mathbf{x}^\\top =  [\\ln k, \\alpha, \\beta]$.\n",
    "Each of the rows of $\\mathbf{A}$ will have the following representation, $\\mathbf{a}_i^\\top = [1, \\ln [NO], \\ln [H_2]]$, and $\\mathbf{b} = \\ln (\\text{Initial Rates})$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(\n",
    "    #code here\n",
    ")\n",
    "A = np.log(A)\n",
    "# why the np.ones(3,)?\n",
    "A = # code here\n",
    "\n",
    "b = np.array([#code here])\n",
    "b = np.log(b)\n",
    "\n",
    "# solve for x\n",
    "# code here\n",
    "\n",
    "ln_k = x[0]\n",
    "alpha = x[1]\n",
    "beta = x[2]\n",
    "print(f\"ln(k) = {ln_k:.4f}\", f\"k = {np.exp(ln_k):.4f}\")\n",
    "print(f\"alpha = {alpha:.2f}\")\n",
    "print(f\"beta = {beta:.2f}\")\n",
    "\n",
    "# you can compare your results with\n",
    "x_numpy = np.linalg.solve(A, b)\n",
    "\n",
    "ln_k = x_numpy[0]\n",
    "alpha = x_numpy[1]\n",
    "beta = x_numpy[2]\n",
    "print(f\"ln(k) = {ln_k:.4f}\", f\"k = {np.exp(ln_k):.4f}\")\n",
    "print(f\"alpha = {alpha:.2f}\")\n",
    "print(f\"beta = {beta:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Non-Square Matrix solutions (Overdetermined)\n",
    "\n",
    "Linear equations as you know could also describe problems where have either more points (rows) than features (columns), ir vice versa more features (columns) than points (rows).<br>\n",
    "The case where the number of points is bigger than the number of columns is known as **Overdetermined**. \n",
    "Because $\\mathbf{A}$ is not a square matrix, \n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix} a_{1,1} & a_{1,2} & \\cdots & a_{1,m} \\\\\\\\ a_{2,1} & a_{2,2} & \\cdots & a_{2,m} \\\\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\\\ a_{n-1,1} & a_{n-1, 2} & \\cdots & a_{n-1, m} \\\\ a_{n,1} & a_{n,2} & \\cdots & a_{n,m} \\end{bmatrix},\n",
    "$$\n",
    "where $n > m$.<br>\n",
    "We can approximate the inverse of these matrix using Singular Value Decomposition (SVD) [link](https://sthalles.github.io/svd-for-regression/).\n",
    "\n",
    "## Singular Value Decomposition\n",
    "The SVD of a matrix $\\mathbf{A}$ is given by\n",
    "$$\n",
    "\\mathbf{A} = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^T\n",
    "$$\n",
    "where $\\mathbf{U}$ and $\\mathbf{V}^T$ are orthogonal matrices,\n",
    "$$\n",
    "\\mathbf{U}^T \\mathbf{U} = \\mathbf{I} \\\\\n",
    "\\mathbf{V}^T \\mathbf{V} = \\mathbf{I},\n",
    "$$\n",
    "and $\\mathbf{\\Sigma}$ is a diagonal matrix with non-negative real numbers on the diagonal.\n",
    "\n",
    "\n",
    "Due to the shortness of the course we will not properly review SVDs, but is one of the main building blocks in scientific computing. <br>\n",
    "\n",
    "\n",
    "## Linear Equations using SVD\n",
    "The idea if SVD is to approximate the inverse of $\\mathbf{A}$. \n",
    "$$\n",
    "\\mathbf{A} \\mathbf{x} = \\mathbf{b} \\\\\n",
    "\\underbrace{\\left(\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^\\top \\right)}_{\\mathbf{A}}\\mathbf{x} =\\mathbf{b} \\\\\n",
    "\\left(\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^\\top \\right)^{-1} \\left(\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^\\top \\right)\\mathbf{x} = \\left(\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^\\top \\right)^{-1} \\mathbf{b} \\\\\n",
    "\\mathbf{V}\\mathbf{\\Sigma}^{-1}\\mathbf{U}^\\top \\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^\\top \\mathbf{x} = \\left(\\mathbf{V}\\mathbf{\\Sigma}^{-1}\\mathbf{U}^\\top \\right) \\mathbf{b},\n",
    "$$\n",
    "whe can cancel some terms, using the orthogonality property of $\\mathbf{U}$ and $\\mathbf{V}$, giving us, \n",
    "$$\n",
    "\\mathbf{x} = \\mathbf{V}\\mathbf{\\Sigma}^{-1}\\mathbf{U}^\\top \\mathbf{b} \\\\\n",
    "\\mathbf{x} = \\mathbf{A}^{+} \\mathbf{b},\n",
    "$$\n",
    "where $\\mathbf{A}^{+}$ is known as the *pseudo* inverse of $\\mathbf{A}$; $\\mathbf{A}^{+} \\mathbf{A} \\approx \\mathbf{I}$.\n",
    "\n",
    "\n",
    "Extra:<br>\n",
    "* $\\left(\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^\\top \\right)^{-1} = \\left(\\mathbf{V}\\mathbf{\\Sigma}^{-1}\\mathbf{U}^\\top \\right)$ is explained in Eq. 223 of [The Matrix Cookbook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf)\n",
    "\n",
    "\n",
    "You can get the SVD of any matrix in Numpy using the following code, \n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "X = np.random.rand(10, 3) # 10 rows, 3 columns\n",
    "# Perform SVD on X\n",
    "U, S, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.random.rand(10, 3)  # 10 rows, 3 columns\n",
    "print('Matrix A')\n",
    "print(A)\n",
    "print('----------------------------------------------------------------')\n",
    "# Perform SVD on X\n",
    "U, S, Vt = np.linalg.svd(A, full_matrices=False)\n",
    "V = Vt.T\n",
    "print('U: ',U.shape, 'S: ', S.shape, 'V:', V.shape)\n",
    "print(U.T@U)\n",
    "print(Vt@V)\n",
    "print(S)\n",
    "print('----------------------------------------------------------------')\n",
    "S_inv = np.diag(1 / S)\n",
    "A_pinv = Vt.T @ S_inv @ U.T\n",
    "print('Psuedoinverse of A')\n",
    "print(A_pinv.shape)\n",
    "print(A_pinv)\n",
    "print('----------------------------------------------------------------')\n",
    "# reconstruct A = U Sigma V^T\n",
    "A_rec = U @ np.diag(S) @ Vt\n",
    "print('Reconstructed Matrix A')\n",
    "print(A_rec)\n",
    "print('----------------------------------------------------------------')\n",
    "print('A+ A = I')\n",
    "print(A_pinv@A)\n",
    "print('----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many components de we need to reconstruct A\n",
    "for i in range(3): \n",
    "    A_a = U[:, :i] @ np.diag(S[:i]) @ Vt[:i,:]\n",
    "    error = np.linalg.norm(A_a - A)\n",
    "    print(f\"Error in reconstructed matrix for {i+1} components: {error:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the following data, where we have more experiments than partial orders and rate constant. Example from [link](https://chem.libretexts.org/Bookshelves/General_Chemistry/Chemistry_1e_(OpenSTAX)/12%3A_Kinetics/12.04%3A_Rate_Laws). <br>\n",
    "\n",
    "The reaction we are studying is, \n",
    "$$\n",
    "NO(g) + O_3(g) \\to NO_2(g) + O_2(g)\n",
    "$$\n",
    "\n",
    "Then we collected the following measured the concentrations of this reactions and it's rates, \n",
    "\n",
    "| Experiment | [NO] | [O<sub>4</sub>] | Initial Rate [M/s]\n",
    "| :---: | :---: | :---: | :---: |\n",
    "1 |\t1.00 × 10−6 |\t3.00 × 10−6 |\t6.60 × 10−5\n",
    "2 |\t1.00 × 10−6 |\t6.00 × 10−6 |\t1.32 × 10−4\n",
    "3 |\t1.00 × 10−6 |\t9.00 × 10−6 |\t1.98 × 10−4\n",
    "4 |\t2.00 × 10−6 |\t9.00 × 10−6 |\t3.96 × 10−4\n",
    "5 |\t3.00 × 10−6 |\t9.00 × 10−6 |\t5.94 × 10−4\n",
    "\n",
    "\n",
    "The rate law for this reaction has the following form,\n",
    "$$\n",
    "r = k [NO]^{\\alpha}[O_3]^{\\beta}.\n",
    "$$\n",
    "\n",
    "*We could choose only 3 of those experiments randomly and solve this problem using the square matrix approach.<br> \n",
    "I leave you this as exercise/homework, you can also average these numbers over different random experiments selected multiple times. <br>\n",
    "\n",
    "\n",
    "Here, we will choose the SVD approach to find $\\ln k$, $\\alpha$, and $\\beta$.<br>\n",
    "Again, we can transform the rate law into a linear system of equations using the logarithm,\n",
    "$$\n",
    "\\ln r = \\ln k +  \\alpha \\ln [NO] + \\beta\\ln [O_3].\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Equations using SVD\n",
    "A = np.array([[1E-6,3E-6],\n",
    "             [1E-6,6E-6],\n",
    "             [1E-6,9E-6],\n",
    "             [2E-6,9E-6],\n",
    "             [3E-6,9E-6]])\n",
    "A = np.log(A)\n",
    "A = np.column_stack((np.ones(A.shape[0],), A))  # why the np.ones(3,)?\n",
    "\n",
    "b = np.array([6.6E-5,1.32E-4,1.98E-4,3.96E-4,5.94E-4])\n",
    "b = np.log(b)\n",
    "\n",
    "# Step 1: Perform SVD on X\n",
    "\n",
    "\n",
    "# Step 2: Compute the pseudo-inverse of the singular values\n",
    "\n",
    "\n",
    "# Step 3: Calculate the pseudo-inverse of X using U, S_inv, and Vt\n",
    "\n",
    "\n",
    "# Step 4: Compute the weight vector (regression coefficients) w\n",
    "\n",
    "\n",
    "ln_k = x[0]\n",
    "alpha = x[1]\n",
    "beta = x[2]\n",
    "print(f\"ln(k) = {ln_k:.4f}\", f\"k = {np.exp(ln_k):.4f}\")\n",
    "print(f\"alpha = {alpha:.2f}\")\n",
    "print(f\"beta = {beta:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steady State Solution using gradient descent\n",
    "Let's consider the following reaction,\n",
    "$$\n",
    "2NO + Br_2 \\to 2NOBr\n",
    "$$\n",
    "with the forward and reverse equilibrium constants ($k_f$ and $k_r$).\n",
    "\n",
    "We can derive three different rate laws for each species,\n",
    "$$\n",
    "\\frac{d [NO]}{dt} = 2k_b[NOBr]^2 - 2k_f[Br_2][NO]^2\\\\\n",
    "\n",
    "\\frac{d [Br_2]}{dt} = k_b[NOBr]^2 - k_f[Br_2][NO]^2\\\\\n",
    "\n",
    "\\frac{d [NOBr]}{dt} = 2k_f[Br_2][NO]^2 - 2k_b[NOBr]^2\n",
    "$$\n",
    "\n",
    "The goal is to find the values of $[NO], [Br_2]$ and $[NOBr]$,  where $\\frac{d [NO]}{dt} = \\frac{d [Br_2]}{dt} = \\frac{d [NOBr]}{dt} = 0$.<br>\n",
    "\n",
    "\n",
    "For these conditions we can use gradient descent to find these steady state concentrations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-dependent Ordinary differential equations.\n",
    "\n",
    "For the previous reaction, we see that this is a time dependent process, and the steady-state solution only tells us the concentrations at equilibrium but not the time it takes to reach the equilibrium of the reaction.<br>\n",
    "To solve this problem, we can use the method of numerical integration.<br>\n",
    "For example, we can use the Euler method, which we will cover in the next class, or other method of numerical integration for ODEs. <br>\n",
    "\n",
    "The main idea of an ODE is to solve the differential equations in time, giving us, for this case, the concentration of each species at different times.<br>\n",
    "For this, we will use the Scipy library, which contains many numerical integrators for ODEs./\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint\n",
    "def equations_of_motion(x, t, kf, kb):\n",
    "    rf = kf * x[0]**2 * x[1]\n",
    "    rb = kb * x[2]**2\n",
    "    return [2*(rb - rf), rb - rf, 2*(rf - rb)]\n",
    "\n",
    "t_grid = np.linspace(0,20,100)\n",
    "k_vals = 0.42, 0.17 #kf, kb\n",
    "y0 = np.array([1, 1, 0]) # initial concentrations\n",
    "y_tgrid = odeint(equations_of_motion, y0, t_grid, k_vals)  # EXERCISE: rhs, y0, tout, k_vals\n",
    "print(y_tgrid)\n",
    "\n",
    "print('Steady State')\n",
    "xss_odeint = y_tgrid[-1, :]\n",
    "print(xss_odeint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_grid, y_tgrid)\n",
    "_ = plt.legend(['NO', 'Br$_2$', 'NOBr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent for the Steady State\n",
    "For these conditions we can use gradient descent to find these steady state concentrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equations_of_motion(x, kf, kb):\n",
    "    rf = kf * x[0]**2 * x[1]\n",
    "    rb = kb * x[2]**2\n",
    "    return [2*(rb - rf), rb - rf, 2*(rf - rb)]\n",
    "\n",
    "\n",
    "def gradient_of_equations_of_motion(x, kf, kb):\n",
    "    dg1_dx1 = -4*kf*x[1]*x[0]\n",
    "    dg1_dx2 = -2*kf*x[0]**2\n",
    "    dg1_dx3 = 4*kb*x[2]\n",
    "\n",
    "    dg2_dx1 = -2*kf*x[1]*x[0]\n",
    "    dg2_dx2 = -kf*x[0]**2\n",
    "    dg2_dx3 = 2*kb*x[2]\n",
    "\n",
    "    dg3_dx1 = 4*kf*x[1]*x[0]\n",
    "    dg3_dx2 = 2*kf*x[0]**2\n",
    "    dg3_dx3 = -4*kb*x[2]\n",
    "\n",
    "    jac = np.array([[dg1_dx1, dg1_dx2, dg1_dx3],\n",
    "                    [dg2_dx1, dg2_dx2, dg2_dx3],\n",
    "                    [dg3_dx1, dg3_dx2, dg3_dx3]])\n",
    "    return jac\n",
    "\n",
    "\n",
    "def error_function(x, kf, kb):\n",
    "    g = equations_of_motion(x, kf, kb)\n",
    "    return 0.5 * np.dot(g, g)\n",
    "\n",
    "\n",
    "def gradient_error_function(x, kf, kb):\n",
    "    g = equations_of_motion(x, kf, kb)\n",
    "    jac_g = gradient_of_equations_of_motion(x, kf, kb)\n",
    "    return jac_g.T @ g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x0 = np.array([0.45, 0.45, 0.45])\n",
    "x0 = np.random.uniform(0.,0.01,size=(3,)) + np.array([0.42940398, 0.71470199, 0.57059602])\n",
    "kf, kb = 0.42, 0.17\n",
    "\n",
    "eta = 0.02\n",
    "for i in range(1000):\n",
    "    dx0 = gradient_error_function(x0, kf, kb)\n",
    "    e = error_function(x0, kf, kb)\n",
    "    print(f'Itr {i+1}, e = ', e, 'x = ', x0, '|dx| = ', np.linalg.norm(dx0))\n",
    "    x0 = x0 - eta * dx0\n",
    "\n",
    "xss_gd = x0\n",
    "print('Steady State concentrations')\n",
    "print(f'[NO] = {x0[0]:.3f}')\n",
    "print(r'[Br2]' + f' = {x0[1]:.3f}')\n",
    "print(f'[NOBr] = {x0[2]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem3pc3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
